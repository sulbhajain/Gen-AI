{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T05:21:44.773739Z","iopub.execute_input":"2025-08-30T05:21:44.774104Z","iopub.status.idle":"2025-08-30T05:21:44.781215Z","shell.execute_reply.started":"2025-08-30T05:21:44.774076Z","shell.execute_reply":"2025-08-30T05:21:44.780098Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"!pip install -q deepeval","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T05:21:46.140505Z","iopub.execute_input":"2025-08-30T05:21:46.140851Z","iopub.status.idle":"2025-08-30T05:21:50.538978Z","shell.execute_reply.started":"2025-08-30T05:21:46.140827Z","shell.execute_reply":"2025-08-30T05:21:50.537649Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"!pip install -q openai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T05:21:50.540967Z","iopub.execute_input":"2025-08-30T05:21:50.541345Z","iopub.status.idle":"2025-08-30T05:21:54.628003Z","shell.execute_reply.started":"2025-08-30T05:21:50.541310Z","shell.execute_reply":"2025-08-30T05:21:54.626871Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"%env OPENAI_API_KEY= \"Key\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T05:28:28.002064Z","iopub.execute_input":"2025-09-26T05:28:28.002281Z","iopub.status.idle":"2025-09-26T05:28:28.011088Z","shell.execute_reply.started":"2025-09-26T05:28:28.002260Z","shell.execute_reply":"2025-09-26T05:28:28.010137Z"}},"outputs":[{"name":"stdout","text":"env: OPENAI_API_KEY=\"Key\"\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nos.environ[\"OPENAI_API_KEY\"] = \"key\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T05:28:28.013355Z","iopub.execute_input":"2025-09-26T05:28:28.013624Z","iopub.status.idle":"2025-09-26T05:28:28.042412Z","shell.execute_reply.started":"2025-09-26T05:28:28.013604Z","shell.execute_reply":"2025-09-26T05:28:28.041232Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import deepeval\n\ndeepeval.login_with_confident_api_key(None)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T05:41:00.309747Z","iopub.execute_input":"2025-08-30T05:41:00.310089Z","iopub.status.idle":"2025-08-30T05:41:00.597973Z","shell.execute_reply.started":"2025-08-30T05:41:00.310060Z","shell.execute_reply":"2025-08-30T05:41:00.596422Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/2272239166.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeepeval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdeepeval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogin_with_confident_api_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: module 'deepeval' has no attribute 'login_with_confident_api_key'"],"ename":"AttributeError","evalue":"module 'deepeval' has no attribute 'login_with_confident_api_key'","output_type":"error"}],"execution_count":14},{"cell_type":"code","source":"from deepeval import evaluate\nfrom deepeval.metrics import AnswerRelevancyMetric\nfrom deepeval.test_case import LLMTestCase\nfrom deepeval.tracing import observe, update_current_span\n\nanswer_relevancy_metric = AnswerRelevancyMetric(threshold=0.7)\n\n\ntest_case = LLMTestCase(\n    input=\"What if these shoes don't fit?\",\n    # Replace this with the actual output from your LLM application\n    actual_output=\"We offer a 30-day full refund at no extra costs.\",\n    retrieval_context=[\"All customers are eligible for a 30 day full refund at no extra costs.\"]\n)\n\nevaluate([test_case], [answer_relevancy_metric])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T05:39:46.006876Z","iopub.execute_input":"2025-08-30T05:39:46.007866Z","iopub.status.idle":"2025-08-30T05:39:57.273539Z","shell.execute_reply.started":"2025-08-30T05:39:46.007831Z","shell.execute_reply":"2025-08-30T05:39:57.272220Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-\u001b[0m\u001b[1;38;2;55;65;81m4.1\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">4.1</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e932b87c83b1428d97934979ecea81d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}},{"name":"stdout","text":"\n======================================================================\n\nMetrics Summary\n\n  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.7, strict: False, evaluation model: gpt-4.1, reason: The score is 1.00 because the answer was fully relevant and addressed the question directly without any irrelevant information. Great job staying focused and helpful!, error: None)\n\nFor test case:\n\n  - input: What if these shoes don't fit?\n  - actual output: We offer a 30-day full refund at no extra costs.\n  - expected output: None\n  - context: None\n  - retrieval context: ['All customers are eligible for a 30 day full refund at no extra costs.']\n\n======================================================================\n\nOverall Metric Pass Rates\n\nAnswer Relevancy: 100.00% pass rate\n\n======================================================================\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\n\n\u001b[38;2;5;245;141m‚úì\u001b[0m Evaluation completed üéâ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m4.\u001b[0m9s | token cost: \u001b[1;36m0.0034419999999999997\u001b[0m USD\u001b[1m)\u001b[0m\n¬ª Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n   ¬ª Pass Rate: \u001b[1;36m100.0\u001b[0m% | Passed: \u001b[1;32m1\u001b[0m | Failed: \u001b[1;31m0\u001b[0m\n\n ================================================================================ \n\n¬ª What to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n  ¬ª Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n\n\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n\n<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.</span>9s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0034419999999999997</span> USD<span style=\"font-weight: bold\">)</span>\n¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0</span>\n\n ================================================================================ \n\n¬ª What to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n\n\n</pre>\n"},"metadata":{}},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"EvaluationResult(test_results=[TestResult(name='test_case_0', success=True, metrics_data=[MetricData(name='Answer Relevancy', threshold=0.7, success=True, score=1.0, reason='The score is 1.00 because the answer was fully relevant and addressed the question directly without any irrelevant information. Great job staying focused and helpful!', strict_mode=False, evaluation_model='gpt-4.1', error=None, evaluation_cost=0.0034419999999999997, verbose_logs='Statements:\\n[\\n    \"We offer a 30-day full refund.\",\\n    \"There are no extra costs for the refund.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]')], conversational=False, multimodal=False, input=\"What if these shoes don't fit?\", actual_output='We offer a 30-day full refund at no extra costs.', expected_output=None, context=None, retrieval_context=['All customers are eligible for a 30 day full refund at no extra costs.'], additional_metadata=None)], confident_link=None)"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"import pytest\nfrom deepeval import assert_test\nfrom deepeval.metrics import GEval\nfrom deepeval.test_case import LLMTestCase, LLMTestCaseParams\n\n@observe()\ndef test_case():\n    correctness_metric = GEval(\n        name=\"Correctness\",\n        criteria=\"Determine if the 'actual output' is correct based on the 'expected output'.\",\n        evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT, LLMTestCaseParams.EXPECTED_OUTPUT],\n        threshold=0.5\n    )\n    test_case = LLMTestCase(\n        input=\"What if these shoes don't fit?\",\n        # Replace this with the actual output from your LLM application\n        actual_output=\"You have 30 days to get a full refund at no extra cost.\",\n        expected_output=\"We offer a 30-day full refund at no extra costs.\",\n        retrieval_context=[\"All customers are eligible for a 30 day full refund at no extra costs.\"]\n    )\n    assert_test(test_case, [correctness_metric])\n\ntest_case()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T05:39:57.652281Z","iopub.execute_input":"2025-08-30T05:39:57.652632Z","iopub.status.idle":"2025-08-30T05:40:01.492271Z","shell.execute_reply.started":"2025-08-30T05:39:57.652599Z","shell.execute_reply":"2025-08-30T05:40:01.491268Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f047d1911824ac689a72d97bbde0e61"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1;2m[\u001b[0m\u001b[2mConfident AI Trace Log\u001b[0m\u001b[1;2m]\u001b[0m  \u001b[31mNo Confident AI API key found. Skipping trace posting.\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">[</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Confident AI Trace Log</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">]</span>  <span style=\"color: #800000; text-decoration-color: #800000\">No Confident AI API key found. Skipping trace posting.</span>\n</pre>\n"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"from deepeval.metrics import AnswerRelevancyMetric\nfrom deepeval.test_case import LLMTestCase\n\nanswer_relevancy_metric = AnswerRelevancyMetric(threshold=0.7)\ntest_case = LLMTestCase(\n    input=\"What if these shoes don't fit?\",\n    # Replace this with the actual output from your LLM application\n    actual_output=\"We offer a 30-day full refund at no extra costs.\",\n    retrieval_context=[\"All customers are eligible for a 30 day full refund at no extra costs.\"]\n)\n\nanswer_relevancy_metric.measure(test_case)\nprint(answer_relevancy_metric.score)\n# All metrics also offer an explanation\nprint(answer_relevancy_metric.reason)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T05:45:07.880403Z","iopub.execute_input":"2025-08-30T05:45:07.880746Z","iopub.status.idle":"2025-08-30T05:45:11.959952Z","shell.execute_reply.started":"2025-08-30T05:45:07.880720Z","shell.execute_reply":"2025-08-30T05:45:11.958915Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}},{"name":"stdout","text":"1.0\nThe score is 1.00 because the answer was fully relevant and addressed the question directly without any irrelevant information. Great job staying focused and helpful!\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"for tt in dataset.test_cases:\n    print (\" ===== test case ====\")\n    print (tt)\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T07:17:37.991236Z","iopub.execute_input":"2025-08-28T07:17:37.991729Z","iopub.status.idle":"2025-08-28T07:17:37.996766Z","shell.execute_reply.started":"2025-08-28T07:17:37.991705Z","shell.execute_reply":"2025-08-28T07:17:37.995854Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"actual_output = \"We offer a 30-day full refund at no extra cost.\"\nmetric = AnswerRelevancyMetric(\n    threshold=0.7,\n    # model=custom_llm,\n    include_reason=True\n)\ntest_case = LLMTestCase(\n    input=\"What if these shoes don't fit?\",\n    expected_output=\"You're eligible for a 30 day refund at no extra cost.\",\n    actual_output=actual_output,\n    context=[\"All customers are eligible for a 30 day full refund at no extra cost.\"],\n    retrieval_context=[\"Only shoes can be refunded.\"]\n)\nscore = metric.measure(test_case)\nprint(f\"Score: {metric.score}\")         # e.g., 1.0\nprint(f\"Reason: {metric.reason}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T05:45:16.180700Z","iopub.execute_input":"2025-08-30T05:45:16.181550Z","iopub.status.idle":"2025-08-30T05:45:20.301881Z","shell.execute_reply.started":"2025-08-30T05:45:16.181519Z","shell.execute_reply":"2025-08-30T05:45:20.300530Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}},{"name":"stdout","text":"Score: 1.0\nReason: The score is 1.00 because the answer was fully relevant and addressed the question directly without any irrelevant information. Great job staying focused and helpful!\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"from deepeval.metrics import BaseMetric\nfrom deepeval.test_case import LLMTestCase\n\nclass MyCustomMetric(BaseMetric):\n    def measure(self, test_case: LLMTestCase):\n        output = test_case.actual_output.lower()\n        if \"important\" in output:\n            self.score = 1.0\n            self.reason = \"'important' found in output\"\n        else:\n            self.score = 0.0\n            self.reason = \"'important' missing in output\"\n        return self.score\n# Usage example\ntest_case = LLMTestCase(\n    input=\"Explain the significance.\",\n    expected_output=\"This is important.\",\n    actual_output=\"This is very important.\"\n)\nmetric = MyCustomMetric()\nscore = metric.measure(test_case)\nprint(f\"Custom Metric Score: {score}, Reason: {metric.reason}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T05:45:20.305360Z","iopub.execute_input":"2025-08-30T05:45:20.305696Z","iopub.status.idle":"2025-08-30T05:45:20.313197Z","shell.execute_reply.started":"2025-08-30T05:45:20.305673Z","shell.execute_reply":"2025-08-30T05:45:20.312358Z"}},"outputs":[{"name":"stdout","text":"Custom Metric Score: 1.0, Reason: 'important' found in output\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import pytest\nfrom deepeval import assert_test\nfrom deepeval.dataset import EvaluationDataset, Golden\nfrom deepeval.metrics import AnswerRelevancyMetric\nfrom deepeval.test_case import LLMTestCase\n\ndataset = EvaluationDataset(goldens=[Golden(input=\"What's the weather like today?\")\n                                     # , Golden(input=\"What's the weather like today?\")\n                                    ])\n\nfor golden in dataset.goldens:\n    test_case = LLMTestCase(\n        input=golden.input,\n        actual_output= \"The weather is nice and lovely.\" #your_llm_app(golden.input)\n    )\n    dataset.add_test_case(test_case)\n\n@pytest.mark.parametrize(\n    \"test_case\",\n    dataset,\n)\ndef test_customer_chatbot(test_case: LLMTestCase):\n    answer_relevancy_metric = AnswerRelevancyMetric(threshold=0.5)\n    assert_test(test_case, [answer_relevancy_metric])\n\ntest_case_new = LLMTestCase(\n        input=golden.input,\n        actual_output= \"The ball is red.\" #your_llm_app(golden.input)\n    )\ntest_customer_chatbot(test_case= test_case) # passes \ntest_customer_chatbot(test_case= test_case_new) # fails","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T05:45:22.602317Z","iopub.execute_input":"2025-08-30T05:45:22.602636Z","iopub.status.idle":"2025-08-30T05:45:31.256831Z","shell.execute_reply.started":"2025-08-30T05:45:22.602612Z","shell.execute_reply":"2025-08-30T05:45:31.255825Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba85793cd56f4281bb3a8abf481f5db2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"946a3c69fea94378975a668f82671c01"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3062257708.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     )\n\u001b[1;32m     30\u001b[0m \u001b[0mtest_customer_chatbot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_case\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtest_case\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# passes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mtest_customer_chatbot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_case\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtest_case_new\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# fails\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_36/3062257708.py\u001b[0m in \u001b[0;36mtest_customer_chatbot\u001b[0;34m(test_case)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_customer_chatbot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_case\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLLMTestCase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0manswer_relevancy_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAnswerRelevancyMetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0massert_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_case\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0manswer_relevancy_metric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m test_case_new = LLMTestCase(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/deepeval/evaluate/evaluate.py\u001b[0m in \u001b[0;36massert_test\u001b[0;34m(test_case, metrics, golden, observed_callback, run_async)\u001b[0m\n\u001b[1;32m    182\u001b[0m             ]\n\u001b[1;32m    183\u001b[0m         )\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Metrics: {failed_metrics_str} failed.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAssertionError\u001b[0m: Metrics: Answer Relevancy (score: 0.0, threshold: 0.5, strict: False, error: None, reason: The score is 0.00 because the response discussed the color of a ball, which is completely unrelated to the question about today's weather.) failed."],"ename":"AssertionError","evalue":"Metrics: Answer Relevancy (score: 0.0, threshold: 0.5, strict: False, error: None, reason: The score is 0.00 because the response discussed the color of a ball, which is completely unrelated to the question about today's weather.) failed.","output_type":"error"}],"execution_count":18},{"cell_type":"code","source":"from deepeval.tracing import observe, update_current_span\nfrom deepeval.test_case import LLMTestCase\nfrom deepeval.dataset import Golden\nfrom deepeval.metrics import GEval\nfrom deepeval import evaluate\n\ncorrectness = GEval(name=\"Correctness\", criteria=\"Determine if the 'actual output' is correct based on the 'expected output'.\", evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT, LLMTestCaseParams.EXPECTED_OUTPUT])\n\n@observe(metrics=[correctness])\ndef inner_component():\n    # Component can be anything from an LLM call, retrieval, agent, tool use, etc.\n    update_current_span(test_case=LLMTestCase(input=\"...\", actual_output=\"...\"))\n    return\n\n@observe\ndef llm_app(input: str):\n    inner_component()\n    return\n\nevaluate(observed_callback=llm_app, goldens=[Golden(input=\"Hi!\")])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T05:49:45.138903Z","iopub.execute_input":"2025-08-30T05:49:45.139661Z","iopub.status.idle":"2025-08-30T05:49:45.220769Z","shell.execute_reply.started":"2025-08-30T05:49:45.139630Z","shell.execute_reply":"2025-08-30T05:49:45.219458Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/2651421383.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobserved_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm_app\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoldens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGolden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Hi!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: evaluate() got an unexpected keyword argument 'observed_callback'"],"ename":"TypeError","evalue":"evaluate() got an unexpected keyword argument 'observed_callback'","output_type":"error"}],"execution_count":25},{"cell_type":"code","source":"from openai import OpenAI\nfrom deepeval.tracing import observe\n\nclient = OpenAI()\n\n@observe()\ndef get_res(query: str):\n    response = client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=[{\"role\": \"user\", \"content\": query}]\n    ).choices[0].message.content\n\n    return response\nget_res(\"What is the weather today?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T05:45:53.910699Z","iopub.execute_input":"2025-08-30T05:45:53.911046Z","iopub.status.idle":"2025-08-30T05:45:55.658939Z","shell.execute_reply.started":"2025-08-30T05:45:53.911001Z","shell.execute_reply":"2025-08-30T05:45:55.658130Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1;2m[\u001b[0m\u001b[2mConfident AI Trace Log\u001b[0m\u001b[1;2m]\u001b[0m  \u001b[31mNo Confident AI API key found. Skipping trace posting.\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">[</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Confident AI Trace Log</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">]</span>  <span style=\"color: #800000; text-decoration-color: #800000\">No Confident AI API key found. Skipping trace posting.</span>\n</pre>\n"},"metadata":{}},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"\"I'm unable to provide real-time information, including current weather updates. For the most accurate and up-to-date weather information, please check a reliable weather website or app.\""},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"from openai import OpenAI\nfrom deepeval.tracing import observe, update_current_span\nfrom deepeval.test_case import LLMTestCase\n\nclient = OpenAI()\n\n@observe()\ndef get_res(query: str):\n    response = client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=[{\"role\": \"user\", \"content\": query}]\n    ).choices[0].message.content\n\n    update_current_span(input=query, output=response)\n    return response","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T05:46:02.606372Z","iopub.execute_input":"2025-08-30T05:46:02.606715Z","iopub.status.idle":"2025-08-30T05:46:02.676492Z","shell.execute_reply.started":"2025-08-30T05:46:02.606693Z","shell.execute_reply":"2025-08-30T05:46:02.675548Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"get_res(\"What is the weather today?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T05:46:03.761544Z","iopub.execute_input":"2025-08-30T05:46:03.761942Z","iopub.status.idle":"2025-08-30T05:46:04.648592Z","shell.execute_reply.started":"2025-08-30T05:46:03.761920Z","shell.execute_reply":"2025-08-30T05:46:04.647571Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1;2m[\u001b[0m\u001b[2mConfident AI Trace Log\u001b[0m\u001b[1;2m]\u001b[0m  \u001b[31mNo Confident AI API key found. Skipping trace posting.\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">[</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Confident AI Trace Log</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">]</span>  <span style=\"color: #800000; text-decoration-color: #800000\">No Confident AI API key found. Skipping trace posting.</span>\n</pre>\n"},"metadata":{}},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"\"I'm unable to provide real-time information or current weather updates. To find out the weather today, please check a reliable weather website or app.\""},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}