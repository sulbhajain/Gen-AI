{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b96616c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.0 environment at: /Users/suljain/opt/anaconda3/envs/rag_env\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 2ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install numpy==1.26.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5064c626",
   "metadata": {},
   "source": [
    "SBERT/bi-encoder, ColBERT, and cross-encoder/re-ranker are three strategies used for information retrieval in RAG systems.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d41c089",
   "metadata": {},
   "source": [
    "### BERT (Bidirectional Encoder Representations from Transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47ae6631",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suljain/opt/anaconda3/envs/rag_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Load pre-trained BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Example input text\n",
    "text = \"hello world\"\n",
    "\n",
    "# Tokenize input text\n",
    "inputs = tokenizer(text, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff9b1de",
   "metadata": {},
   "source": [
    "![title](image/bert.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57d0c07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'hello', 'world', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea90b1c",
   "metadata": {},
   "source": [
    "Every input begins with a special [CLS] token that signals the start of the text (short for “classification”). The corresponding [CLS] embedding vector contains information about the entire input and can be used for subsequent tasks.\n",
    "\n",
    "BERT can handle either a single sentence or a pair of sentences. If two sentences are involved, they are separated by a distinct [SEP] token that marks the boundary between them.\n",
    "\n",
    "In summary, the BERT encoder model produces an embedding vector for each input token, as well as one or two additional special embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6f44ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "# Pass inputs through BERT model\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Get embedding tensor\n",
    "embeddings = outputs.last_hidden_state\n",
    "print(embeddings.shape) # [batch, number of tokens, embedding dimension]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981cff6f",
   "metadata": {},
   "source": [
    "This means that we have one batch and four embeddings, each with a dimensionality of 768."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920ebc60",
   "metadata": {},
   "source": [
    "### SBERT = Sentence BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a7e635",
   "metadata": {},
   "source": [
    "![title](image/sbert.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36cfefe",
   "metadata": {},
   "source": [
    "While the original BERT model focuses on token-level embeddings, SBERT builds upon BERT to generate meaningful sentence-level embeddings.\n",
    "\n",
    "The key idea behind SBERT is simple yet powerful. It averages the embeddings of all the tokens in a sentence, a technique called mean pooling, to produce a single vector that captures the sentence’s overall meaning.\n",
    "\n",
    "After averaging all the token-level embedding vectors, we can measure the similarity between two vectors using cosine similarity. Cosine similarity yields a value y between -1 and +1, which indicates how similar two vectors are.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "789ee713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7551, 0.5361, 0.0707]])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load a pretrained Sentence Transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# The text to encode\n",
    "query = \"How is the weather today?\"\n",
    "docs = [\n",
    "    \"The weather is lovely today.\",\n",
    "    \"It's so sunny outside!\",\n",
    "    \"I like cats.\",\n",
    "]\n",
    "\n",
    "# Calculate vector embeddings by calling model.encode()\n",
    "query_embedding = model.encode(query)\n",
    "docs_embeddings = model.encode(docs) # we could store these in a database\n",
    "\n",
    "\n",
    "# Calculate the cosine similarities\n",
    "cos_similarities = model.similarity(query_embedding, docs_embeddings)\n",
    "print(cos_similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202e5387",
   "metadata": {},
   "source": [
    "This means that the first document is the best match, while the third document is not.\n",
    "\n",
    "In an RAG system, all document embeddings are stored in a vector database. At runtime, we convert the query text into an embedding vector and search for matches in the vector database. This process is very fast and can be optimized.\n",
    "\n",
    "However, SBERT’s conversion of entire documents (or smaller document chunks) into a single vector leads to information loss and, consequently, a loss of retrieval accuracy. Additionally, with this method, queries and documents are embedded separately. The model never actually “sees” the query and document text together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5e29a2",
   "metadata": {},
   "source": [
    "### Cross-Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96079d7e",
   "metadata": {},
   "source": [
    "![title](image/cross-encoder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec6534a",
   "metadata": {},
   "source": [
    "Unlike SBERT, which treats the query and document independently, a re-ranker looks at them together and predicts a relevance score y that reflects how well the document answers the query. The higher the score, the better the match. The [CLS] embedding can be used as input for a small neural network that is trained to produce relevance scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52f21294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'corpus_id': 0, 'score': 8.2618475, 'text': 'The weather is lovely today.'}, {'corpus_id': 1, 'score': -7.8940616, 'text': \"It's so sunny outside!\"}, {'corpus_id': 2, 'score': -11.505094, 'text': 'I like cats.'}]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "# Load a pretrained re-ranker model\n",
    "cross_encoder = CrossEncoder(\n",
    "    \"cross-encoder/ms-marco-TinyBERT-L-2-v2\", max_length=512, device=\"cpu\"\n",
    ")\n",
    "\n",
    "# The text to rank\n",
    "query = \"How is the weather today?\"\n",
    "docs = [\n",
    "    \"The weather is lovely today.\",\n",
    "    \"It's so sunny outside!\",\n",
    "    \"I like cats.\",\n",
    "]\n",
    "\n",
    "# Calculate relevance scores by calling cross_encoder.rank()\n",
    "scores = cross_encoder.rank(\n",
    "    query=query,\n",
    "    documents=docs,\n",
    "    return_documents=True,\n",
    ")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde63f4f",
   "metadata": {},
   "source": [
    "The higher the scores, the better the match between query and document.\n",
    "\n",
    "Unlike SBERT, a re-ranker model sees the query and document text together, allowing it to produce much better results. However, re-ranking is much slower and is usually only applied to the top K results after the initial retrieval stage. For instance, it might re-rank the top 20 documents to find the five most relevant ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfcd7e7",
   "metadata": {},
   "source": [
    "### Colbert = Contextualized Late interaction BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cf94c6",
   "metadata": {},
   "source": [
    "Unlike SBERT, ColBERT does not average BERT’s output embeddings into a single vector. Instead, it works with the token-level embeddings from BERT.\n",
    "\n",
    "To calculate the relevance score between a query and a document using ColBERT, we create a matrix containing the query and document tokens. The cosine similarity between the query token $q$ and the document token $d$ is contained in each cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9eeccd0",
   "metadata": {},
   "source": [
    "![title](image/colbert.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06a75d5",
   "metadata": {},
   "source": [
    "We select the maximum value for each row in that matrix. Then, we sum all the selected values. This $MaxSim$ approach yields a relevance score between a query and a single document. This process must be repeated for all documents.\n",
    "\n",
    "Based on search retrieval accuracy and speed, ColBERT falls between the bi-encoder and the cross-encoder. One downside of ColBERT is that multiple embedding vectors must be stored for each document. This significantly increases the amount of storage needed in a vector database.\n",
    "\n",
    "ColBERT can be used for both first-stage retrieval and as an alternative to a re-ranker for narrowing down retrieved candidates.\n",
    "\n",
    "ColBERT is supported by a few vector databases, such as Qdrant and Weaviate. There is also a Stanford GitHub repository: `stanford-futuredata/ColBERT`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823100f9",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89a0575",
   "metadata": {},
   "source": [
    "The table below summarizes the differences between them. Depending on your use case and requirements, you can use one or a combination of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c115c6",
   "metadata": {},
   "source": [
    "![title](image/summary.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27199c9f",
   "metadata": {},
   "source": [
    "A bi-encoder is the fastest option, but it has the lowest retrieval accuracy. ColBERT is slower and requires more vector storage, but its accuracy is better than that of the bi-encoder. Both methods can be used to retrieve documents based on a query.\n",
    "\n",
    "A re-ranker is typically used in the second stage of retrieval to narrow down the list of candidates. Re-rankers are slow but produce the best results.\n",
    "\n",
    "To achieve optimal results in terms of speed, accuracy, and storage, I recommend using a combination of a bi-encoder and a re-ranker. First, the bi-encoder retrieves an initial set of candidates. Then, the re-ranker narrows down the list to the top results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a7d6a8",
   "metadata": {},
   "source": [
    "### References:\n",
    "1. https://ai.gopubby.com/three-different-retrieval-strategies-in-rag-systems-e9434fd80f35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02355c05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
