{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92e41f2e",
   "metadata": {},
   "source": [
    "### Basic Rag Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d50bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas langchain langchain-openai langchain-community langchain-core openai faiss-cpu python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b88f0a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangChain components for our RAG system\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Load your environment variables\n",
    "load_dotenv(\"key.env\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "print(\"All libraries loaded successfully!\")\n",
    "# print (OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74b88ee",
   "metadata": {},
   "source": [
    "### Reference - https://www.machinelearningplus.com/gen-ai/build-a-simple-rag-system-with-csv-files-step-by-step-guide-for-beginners/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5880af45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c772022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 16 rows from CSV\n",
      "Columns available: ['Name', 'HEX', 'RGB']\n",
      "Data shape: (16, 3)\n",
      "First 5 rows of data:\n",
      "     Name      HEX               RGB\n",
      "0   White  #FFFFFF  rgb(100,100,100)\n",
      "1  Silver  #C0C0C0     rgb(75,75,75)\n",
      "2    Gray  #808080     rgb(50,50,50)\n",
      "3   Black  #000000        rgb(0,0,0)\n",
      "4     Red  #FF0000      rgb(100,0,0)\n"
     ]
    }
   ],
   "source": [
    "# Load your CSV file\n",
    "\n",
    "csv_file_path = \"https://raw.githubusercontent.com/selva86/datasets/refs/heads/master/color_srgb.csv\"  \n",
    "\n",
    "# Replace with your actual file path\n",
    "data_frame = pd.read_csv(csv_file_path)\n",
    "\n",
    "print(f\"Successfully loaded {len(data_frame)} rows from CSV\")\n",
    "print(f\"Columns available: {list(data_frame.columns)}\")\n",
    "print(f\"Data shape: {data_frame.shape}\")\n",
    "\n",
    "# Look at the first few rows to understand our data structure\n",
    "print(\"First 5 rows of data:\")\n",
    "print(data_frame.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b60dda16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_readable_text_from_row(row):\n",
    "    \"\"\"\n",
    "    Convert a single CSV row into a natural language description\n",
    "    \"\"\"\n",
    "    # Customize this based on your CSV structure\n",
    "    # This example assumes columns: Name, HEX, RGB\n",
    "    description_parts = []\n",
    "    for column_name, value in row.items():\n",
    "        if pd.notna(value):  # Only include non-empty values\n",
    "            description_parts.append(f\"{column_name}: {value}\")\n",
    "    # Join everything into one readable sentence\n",
    "    return \". \".join(description_parts) + \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03154846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 16 document objects\n",
      "\n",
      "Examples of converted documents:\n",
      "Document 1: Name: White. HEX: #FFFFFF. RGB: rgb(100,100,100).\n",
      "Document 2: Name: Silver. HEX: #C0C0C0. RGB: rgb(75,75,75).\n",
      "Document 3: Name: Gray. HEX: #808080. RGB: rgb(50,50,50).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert all rows to readable text documents\n",
    "text_documents = []\n",
    "\n",
    "for index, row in data_frame.iterrows():\n",
    "    # Convert each row to readable text\n",
    "    readable_description = create_readable_text_from_row(row)\n",
    "    # Create a Document object (LangChain's format)\n",
    "    doc = Document(page_content=readable_description)\n",
    "    text_documents.append(doc)\n",
    "  \n",
    "print(f\"Created {len(text_documents)} document objects\")\n",
    "\n",
    "# A few examples of what we created\n",
    "\n",
    "print(\"\\nExamples of converted documents:\")\n",
    "for i in range(min(3, len(text_documents))):\n",
    "    print(f\"Document {i+1}: {text_documents[i].page_content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0f37e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding system initialized\n",
      "This will convert our text into numerical vectors that capture meaning\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set up our embedding system\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "print(\"Embedding system initialized\")\n",
    "print(\"This will convert our text into numerical vectors that capture meaning\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66430274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating vector store from documents...\n",
      "Vector store created with 16 documents\n",
      "Each document is now represented as a vector for fast similarity search\n"
     ]
    }
   ],
   "source": [
    "# Create our vector store from the documents\n",
    "print(\"Creating vector store from documents...\")\n",
    "vector_search_store = FAISS.from_documents(text_documents, embedding_model)\n",
    "print(f\"Vector store created with {len(text_documents)} documents\")\n",
    "print(\"Each document is now represented as a vector for fast similarity search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f8a8c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing search for: 'blue color'\n",
      "Found 3 similar documents:\n",
      "\n",
      "Result 1: Name: Blue. HEX: #0000FF. RGB: rgb(0,0,100).\n",
      "\n",
      "Result 2: Name: Purple. HEX: #800080. RGB: rgb(50,0,50).\n",
      "\n",
      "Result 3: Name: Green. HEX: #008000. RGB: rgb(0,50,0).\n"
     ]
    }
   ],
   "source": [
    "# Test our search system\n",
    "test_query = \"blue color\"\n",
    "similar_documents = vector_search_store.similarity_search(test_query, k=3)\n",
    "print(f\"Testing search for: '{test_query}'\")\n",
    "print(f\"Found {len(similar_documents)} similar documents:\")\n",
    "\n",
    "for i, doc in enumerate(similar_documents):\n",
    "    print(f\"\\nResult {i+1}: {doc.page_content}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdfa31ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI assistant initialized\n",
      "Temperature set to 0 for consistent, factual responses\n"
     ]
    }
   ],
   "source": [
    "# Initialize our AI language model\n",
    "ai_assistant = ChatOpenAI(\n",
    "    temperature=0,  # Low temperature = more focused, consistent answers\n",
    "    model=\"gpt-4o-mini\"  # Good balance of quality and cost\n",
    ")\n",
    "\n",
    "print(\"AI assistant initialized\")\n",
    "print(\"Temperature set to 0 for consistent, factual responses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10d74209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document retriever created\n",
      "It will find the 3 most relevant pieces of information for each question\n"
     ]
    }
   ],
   "source": [
    "# Create a retriever from our vector store\n",
    "document_retriever = vector_search_store.as_retriever(\n",
    "    search_kwargs={\"k\": 3}  # Retrieve top 3 most similar documents\n",
    ")\n",
    "\n",
    "print(\"Document retriever created\")\n",
    "print(\"It will find the 3 most relevant pieces of information for each question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "118eacb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt template created\n"
     ]
    }
   ],
   "source": [
    "# Create a prompt template for our AI assistant\n",
    "answer_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a helpful data analyst. Use the following information from the CSV data to answer the user's question accurately.\n",
    "\n",
    "Important instructions:\n",
    "- Only use information from the provided context\n",
    "- If you can't find the answer in the context, say \"I don't have that information in the data\"\n",
    "- Be specific and include relevant details from the data\n",
    "- Keep your answer clear and concise\n",
    "\n",
    "Context from CSV data:\n",
    "{context}\n",
    "\n",
    "User question: {question}\n",
    "Answer:\n",
    "\"\"\")\n",
    "\n",
    "print(\"Prompt template created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ac074ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete RAG pipeline created!\n"
     ]
    }
   ],
   "source": [
    "# Build the complete RAG chain using LCEL\n",
    "rag_pipeline = (\n",
    "    {\n",
    "        \"context\": document_retriever,  # Find relevant documents\n",
    "        \"question\": RunnablePassthrough()  # Pass the question through\n",
    "    }\n",
    "    | answer_prompt  # Format everything into our prompt\n",
    "    | ai_assistant  # Generate the answer\n",
    "    | StrOutputParser()  # Clean up the output\n",
    ")\n",
    "print(\"Complete RAG pipeline created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "670cb1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: What colors are similar to blue?\n",
      "--------------------------------------------------\n",
      "Answer: I don't have that information in the data.\n",
      "============================================================\n",
      "\n",
      "Question: What is the RGB value for red?\n",
      "--------------------------------------------------\n",
      "Answer: The RGB value for red is rgb(100,0,0).\n",
      "============================================================\n",
      "\n",
      "Question: Are there any dark colors in the data?\n",
      "--------------------------------------------------\n",
      "Answer: Yes, there are dark colors in the data. The colors listed include:\n",
      "\n",
      "1. Black - HEX: #000000, RGB: rgb(0,0,0)\n",
      "2. Gray - HEX: #808080, RGB: rgb(50,50,50)\n",
      "3. Maroon - HEX: #800000, RGB: rgb(50,0,0)\n",
      "\n",
      "All of these colors can be considered dark.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Test multiple questions to see how our system handles different queries\n",
    "test_questions = [\n",
    "    \"What colors are similar to blue?\",\n",
    "    \"What is the RGB value for red?\",\n",
    "    \"Are there any dark colors in the data?\"\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    print(f\"\\nQuestion: {question}\")\n",
    "    print(\"-\" * 50)\n",
    "    try:\n",
    "        answer = rag_pipeline.invoke(question)\n",
    "        print(f\"Answer: {answer}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bec3999",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
